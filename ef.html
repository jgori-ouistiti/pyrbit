<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Exponential Forgetting &mdash; PyRBIT 0.1.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="ACT-R" href="actr.html" />
    <link rel="prev" title="Welcome to PyRBIT’s documentation!" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            PyRBIT
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">See also</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">    Home page</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Exponential Forgetting Model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#the-exponential-forgetting-model">The Exponential Forgetting Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#the-ef-class">The EF class</a></li>
<li class="toctree-l2"><a class="reference internal" href="#worked-out-example-with-the-ef-model">Worked out Example with the EF model</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="actr.html">ACT-R Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="memory.html">Memory Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="information.html">Evaluating the informativeness of a schedule</a></li>
<li class="toctree-l1"><a class="reference internal" href="design.html">Comparing block recall percentages, power analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="_autosummary/pyrbit.html">API reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">PyRBIT</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Exponential Forgetting</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/ef.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="exponential-forgetting">
<h1>Exponential Forgetting<a class="headerlink" href="#exponential-forgetting" title="Permalink to this heading"></a></h1>
<section id="the-exponential-forgetting-model">
<h2>The Exponential Forgetting Model<a class="headerlink" href="#the-exponential-forgetting-model" title="Permalink to this heading"></a></h2>
<p>The exponential forgetting (EF) model follows from Ebbinghaus’ forgetting curve.
According to this model, the probability <span class="math notranslate nohighlight">\(p\)</span> for a subject to correctly recall an item is given by</p>
<div class="math notranslate nohighlight">
\[p = \exp{(-\alpha (1-\beta)^k \Delta t)}, \quad \alpha \in \mathbb{R}^+, \beta \in [0,1],\]</div>
<p>where <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span> are two memory parameters, <span class="math notranslate nohighlight">\(k\)</span> is the number of times the item has been previously seen by the subject (repetition number) and <span class="math notranslate nohighlight">\(\Delta_t\)</span> is the time that has elapsed since the last time that item was seen by the subject (delay). The parameter <span class="math notranslate nohighlight">\(\alpha\)</span> (positive) is the initial forgetting rate: the lower <span class="math notranslate nohighlight">\(\alpha\)</span>, the slower the forgetting and the better the recall. This rate gets reduced by <span class="math notranslate nohighlight">\((1-\beta)\)</span> (between 0 and 1) with each repetition which further slows the rate of forgetting, and thus the higher the <span class="math notranslate nohighlight">\(\beta\)</span>, the better the recall.</p>
</section>
<section id="the-ef-class">
<h2>The EF class<a class="headerlink" href="#the-ef-class" title="Permalink to this heading"></a></h2>
<p>See the API Reference</p>
</section>
<section id="worked-out-example-with-the-ef-model">
<h2>Worked out Example with the EF model<a class="headerlink" href="#worked-out-example-with-the-ef-model" title="Permalink to this heading"></a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyrbit.mle_utils</span> <span class="kn">import</span> <span class="n">CI_asymptotical</span><span class="p">,</span> <span class="n">confidence_ellipse</span>
<span class="kn">from</span> <span class="nn">pyrbit.ef</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ExponentialForgetting</span><span class="p">,</span>
    <span class="n">diagnostics</span><span class="p">,</span>
    <span class="n">identify_ef_from_recall_sequence</span><span class="p">,</span>
    <span class="n">ef_observed_information_matrix</span><span class="p">,</span>
    <span class="n">covar_delta_method_log_alpha</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyrbit.mem_utils</span> <span class="kn">import</span> <span class="n">BlockBasedSchedule</span><span class="p">,</span> <span class="n">experiment</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">SEED</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">beta</span> <span class="o">=</span> <span class="mf">0.4</span>

<span class="c1"># Initialize an EF memory model with 1 item</span>
<span class="n">ef</span> <span class="o">=</span> <span class="n">ExponentialForgetting</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="c1"># Helper function for simulation</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">simulate_arbitrary_traj</span><span class="p">(</span><span class="n">ef</span><span class="p">,</span> <span class="n">k_vector</span><span class="p">,</span> <span class="n">deltas</span><span class="p">):</span>
    <span class="n">recall</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">k_vector</span><span class="p">,</span> <span class="n">deltas</span><span class="p">):</span>
        <span class="n">ef</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
        <span class="n">recall</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ef</span><span class="o">.</span><span class="n">query_item</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">recall</span>

<span class="c1"># ============== Simulate some data</span>
<span class="n">k_vector</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
<span class="n">deltas</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
<span class="n">recall_probs</span> <span class="o">=</span> <span class="n">simulate_arbitrary_traj</span><span class="p">(</span><span class="n">ef</span><span class="p">,</span> <span class="n">k_vector</span><span class="p">,</span> <span class="n">deltas</span><span class="p">)</span>
<span class="n">recall</span> <span class="o">=</span> <span class="p">[</span><span class="n">rp</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">rp</span> <span class="ow">in</span> <span class="n">recall_probs</span><span class="p">]</span>
<span class="n">k_repetition</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">k_vector</span><span class="p">]</span>

<span class="c1"># ================ Run diagnostics</span>
<span class="c1"># some options that you can set to tweak the diagnostics output</span>
<span class="n">exponent_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">xbins</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">inf_to_int</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">loglogplot_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">x_bins</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;lin&quot;</span><span class="p">)</span>
<span class="c1"># Run the diagnostics</span>
<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">fg</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">estim</span><span class="p">)</span> <span class="o">=</span> <span class="n">diagnostics</span><span class="p">(</span>
    <span class="n">alpha</span><span class="p">,</span>
    <span class="n">beta</span><span class="p">,</span>
    <span class="n">k_repetition</span><span class="p">,</span>
    <span class="n">deltas</span><span class="p">,</span>
    <span class="n">recall</span><span class="p">,</span>
    <span class="n">exponent_kwargs</span><span class="o">=</span><span class="n">exponent_kwargs</span><span class="p">,</span>
    <span class="n">loglogplot_kwargs</span><span class="o">=</span><span class="n">loglogplot_kwargs</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># ==================== Perform ML Estimation</span>
<span class="c1"># Solver parameters; this should work well and be quite fast</span>
<span class="n">optim_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;method&quot;</span><span class="p">:</span> <span class="s2">&quot;L-BFGS-B&quot;</span><span class="p">,</span> <span class="s2">&quot;bounds&quot;</span><span class="p">:</span> <span class="p">[(</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">)]}</span>
<span class="n">verbose</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">guess</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1e-2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="c1"># Pass all the observed data to the inference function. You can use basin_hopping for more precise estimates but this will take more time, see actr.py for an example. Returns the output of scipy.optimize</span>
<span class="n">inference_results</span> <span class="o">=</span> <span class="n">identify_ef_from_recall_sequence</span><span class="p">(</span>
    <span class="n">recall_sequence</span><span class="o">=</span><span class="n">recall</span><span class="p">,</span>
    <span class="n">deltas</span><span class="o">=</span><span class="n">deltas</span><span class="p">,</span>
    <span class="n">k_vector</span><span class="o">=</span><span class="n">k_repetition</span><span class="p">,</span>
    <span class="n">optim_kwargs</span><span class="o">=</span><span class="n">optim_kwargs</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
    <span class="n">guess</span><span class="o">=</span><span class="n">guess</span><span class="p">,</span>
    <span class="n">basin_hopping</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">basin_hopping_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1">## ==== computing Confidence Intervals and Ellipses</span>

<span class="c1"># Get observed information matrix</span>
<span class="n">J</span> <span class="o">=</span> <span class="n">ef_observed_information_matrix</span><span class="p">(</span>
    <span class="n">recall</span><span class="p">,</span> <span class="n">deltas</span><span class="p">,</span> <span class="o">*</span><span class="n">inference_results</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">k_vector</span><span class="o">=</span><span class="n">k_repetition</span>
<span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Compute covariance matrix:</span>
<span class="n">covar</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">J</span><span class="p">)</span>
<span class="c1"># get 95% confidence intervals</span>
<span class="n">cis</span> <span class="o">=</span> <span class="n">CI_asymptotical</span><span class="p">(</span><span class="n">covar</span><span class="p">,</span> <span class="n">inference_results</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">critical_value</span><span class="o">=</span><span class="mf">1.96</span><span class="p">)</span>
<span class="n">ax_lin</span> <span class="o">=</span> <span class="n">confidence_ellipse</span><span class="p">(</span><span class="n">inference_results</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">covar</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># with log transform --- should be better</span>
<span class="n">transformed_covar</span> <span class="o">=</span> <span class="n">covar_delta_method_log_alpha</span><span class="p">(</span><span class="n">inference_results</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">covar</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">inference_results</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">inference_results</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
<span class="n">cis</span> <span class="o">=</span> <span class="n">CI_asymptotical</span><span class="p">(</span><span class="n">transformed_covar</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">critical_value</span><span class="o">=</span><span class="mf">1.96</span><span class="p">)</span>
<span class="n">ax_log</span> <span class="o">=</span> <span class="n">confidence_ellipse</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">transformed_covar</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax_lin</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;CE with linear scale&quot;</span><span class="p">)</span>
<span class="n">ax_log</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;CE with alpha log scale&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># ========== An example of inference when using a BlockBasedSchedule</span>
<span class="c1"># Define a blockbasedschedule</span>
<span class="n">schedule</span> <span class="o">=</span> <span class="n">BlockBasedSchedule</span><span class="p">(</span>
    <span class="mi">1</span><span class="p">,</span>
    <span class="mi">5</span><span class="p">,</span>
    <span class="p">[</span><span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">2000</span><span class="p">,</span> <span class="mi">86400</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">2000</span><span class="p">],</span>
    <span class="n">repet_trials</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
    <span class="n">sigma_t</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># Alternative way of defining a population as a list</span>
<span class="n">population_model</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">ExponentialForgetting</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mf">2.5</span><span class="p">),</span> <span class="mf">0.75</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">200</span><span class="p">)</span>
<span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">experiment</span><span class="p">(</span>
    <span class="n">population_model</span><span class="p">,</span>
    <span class="n">schedule</span><span class="p">,</span>
    <span class="n">test_blocks</span><span class="o">=</span><span class="p">[</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">3</span><span class="p">,</span>
        <span class="mi">5</span><span class="p">,</span>
        <span class="mi">6</span><span class="p">,</span>
        <span class="mi">8</span><span class="p">,</span>
    <span class="p">],</span>  <span class="c1"># If there are learning vs recall blocks, define which are the test blocks. This changes behavior of the memory model (false recall during test does not count as an extra repetition in the models)</span>
    <span class="n">replications</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># untested for != 1, but is not useful</span>
<span class="p">)</span>

<span class="c1"># make a big one D array out of the recall data, and get the corresponding deltas and ks</span>
<span class="n">r</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">flatten</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span>
    <span class="n">schedule</span><span class="o">=</span><span class="n">schedule</span><span class="p">,</span>
    <span class="n">population_model</span><span class="o">=</span><span class="n">population_model</span><span class="p">,</span>
    <span class="n">test_blocks</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
    <span class="n">get_k_delta</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">replications</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># infer model parameters</span>
<span class="n">optim_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;method&quot;</span><span class="p">:</span> <span class="s2">&quot;L-BFGS-B&quot;</span><span class="p">,</span> <span class="s2">&quot;bounds&quot;</span><span class="p">:</span> <span class="p">[(</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">)]}</span>
<span class="n">verbose</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">guess</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1e-2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="c1"># Pass all the observed data to the inference function. You can use basin_hopping for more precise estimates but this will take more time, see actr.py for an example. Returns the output of scipy.optimize</span>
<span class="n">inference_results</span> <span class="o">=</span> <span class="n">identify_ef_from_recall_sequence</span><span class="p">(</span>
    <span class="n">recall_sequence</span><span class="o">=</span><span class="n">r</span><span class="p">,</span>
    <span class="n">deltas</span><span class="o">=</span><span class="n">d</span><span class="p">,</span>
    <span class="n">k_vector</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
    <span class="n">optim_kwargs</span><span class="o">=</span><span class="n">optim_kwargs</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
    <span class="n">guess</span><span class="o">=</span><span class="n">guess</span><span class="p">,</span>
    <span class="n">basin_hopping</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">basin_hopping_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">J</span> <span class="o">=</span> <span class="n">ef_observed_information_matrix</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="o">*</span><span class="n">inference_results</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">k_vector</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
<span class="n">covar</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">J</span><span class="p">)</span>
<span class="c1"># get 95% confidence intervals</span>
<span class="n">transformed_covar</span> <span class="o">=</span> <span class="n">covar_delta_method_log_alpha</span><span class="p">(</span><span class="n">inference_results</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">covar</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">inference_results</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">inference_results</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
<span class="n">cis</span> <span class="o">=</span> <span class="n">CI_asymptotical</span><span class="p">(</span><span class="n">transformed_covar</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">critical_value</span><span class="o">=</span><span class="mf">1.96</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cis</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Welcome to PyRBIT’s documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="actr.html" class="btn btn-neutral float-right" title="ACT-R" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Julien Gori.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>